{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh_AUmrgHrdb"
      },
      "source": [
        "# Language Detection Classifier Lab: Implementing a Compact Language Detector (Inspired by Google's CLD3)\n",
        "\n",
        "**Welcome to Lab 4!** This lab guides you through building a language classifier using n-gram features and the \"hashing trick\" for efficient feature representation. We'll reimplement key ideas from Google's Compact Language Detector (CLD3) using the Tatoeba dataset (downsampled for this lab).\n",
        "\n",
        "### Learning Objectives\n",
        "- Understand n-gram extraction and feature hashing for text classification.\n",
        "- Implement data processing pipelines (unigrams, bigrams, trigrams → hashed vectors).\n",
        "- Train and evaluate baseline models: Logistic Regression and a simple Neural Network.\n",
        "- Experiment with encodings: Boolean (presence) vs. Relative Frequencies.\n",
        "- (Optional) Extend to learnable embeddings.\n",
        "\n",
        "### Dataset\n",
        "- **Source**: Tatoeba (sentences + translations, downsampled to ~31k train, ~4k val/test sentences across 39 languages).\n",
        "- **Format**: TSV files (`train.tsv`, `val.tsv`, `test.tsv`) with columns: [ID, Language Code, Sentence].\n",
        "- **Access**: The notebook auto-downloads from the course GitHub repo if not local.\n",
        "\n",
        "### Setup Instructions\n",
        "1. Clone the repo: `git clone https://github.com/Azadshokrollahi/Artificial-intelligence-for-data-science-.git`\n",
        "2. Navigate: `cd Lab4`\n",
        "3. Run: `jupyter notebook language_detector_student.ipynb`\n",
        "4. The notebook handles dataset fetching automatically.\n",
        "\n",
        "**Run the cells step-by-step. Fill in the blanks marked with `# TODO: Student Task` and test your implementations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5cfgh5Hrdc",
        "outputId": "6a712fca-fec2-487d-d887-91fbbef28c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Local small_dataset not found. Downloading from GitHub repo...\n",
            "  ↳ train.tsv ← https://raw.githubusercontent.com/Azadshokrollahi/Artificial-intelligence-for-data-science-/main/Lab4/small_dataset/train.tsv\n",
            "  ↳ val.tsv ← https://raw.githubusercontent.com/Azadshokrollahi/Artificial-intelligence-for-data-science-/main/Lab4/small_dataset/val.tsv\n",
            "  ↳ test.tsv ← https://raw.githubusercontent.com/Azadshokrollahi/Artificial-intelligence-for-data-science-/main/Lab4/small_dataset/test.tsv\n",
            "[INFO] Using small dataset at: /content/small_dataset\n",
            "       Train: small_dataset/train.tsv\n",
            "       Val  : small_dataset/val.tsv\n",
            "       Test : small_dataset/test.tsv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ed7a909d910>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# === Dataset Locator (Auto-download from GitHub if needed) ===\n",
        "from pathlib import Path\n",
        "import os\n",
        "import urllib.request  # For downloading if needed\n",
        "\n",
        "FILENAME_TRAIN = \"train.tsv\"\n",
        "FILENAME_VAL   = \"val.tsv\"\n",
        "FILENAME_TEST  = \"test.tsv\"\n",
        "\n",
        "# Candidate locations if you run the notebook from different folders\n",
        "CANDIDATES = [\n",
        "    Path(\"small_dataset\"),\n",
        "    Path(\"Lab4\") / \"small_dataset\",\n",
        "    Path.cwd() / \"small_dataset\",\n",
        "    Path.cwd() / \"Lab4\" / \"small_dataset\",\n",
        "]\n",
        "\n",
        "dataset_dir = next((p for p in CANDIDATES if (p / FILENAME_TRAIN).exists()\n",
        "                    and (p / FILENAME_VAL).exists()\n",
        "                    and (p / FILENAME_TEST).exists()), None)\n",
        "\n",
        "# If not found locally, download directly from Azad's GitHub repo into ./small_dataset\n",
        "if dataset_dir is None:\n",
        "    print(\"[INFO] Local small_dataset not found. Downloading from GitHub repo...\")\n",
        "    dataset_dir = Path(\"small_dataset\")\n",
        "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    base = \"https://raw.githubusercontent.com/Azadshokrollahi/Artificial-intelligence-for-data-science-/main/Lab4/small_dataset\"\n",
        "    for fname in [FILENAME_TRAIN, FILENAME_VAL, FILENAME_TEST]:\n",
        "        url = f\"{base}/{fname}\"\n",
        "        out = dataset_dir / fname\n",
        "        print(f\"  ↳ {fname} ← {url}\")\n",
        "        urllib.request.urlretrieve(url, out)\n",
        "\n",
        "# Final resolved files\n",
        "FILE_TRAIN = str(dataset_dir / FILENAME_TRAIN)\n",
        "FILE_VAL   = str(dataset_dir / FILENAME_VAL)\n",
        "FILE_TEST  = str(dataset_dir / FILENAME_TEST)\n",
        "\n",
        "print(\"[INFO] Using small dataset at:\", dataset_dir.resolve())\n",
        "print(\"       Train:\", FILE_TRAIN)\n",
        "print(\"       Val  :\", FILE_VAL)\n",
        "print(\"       Test :\", FILE_TEST)\n",
        "\n",
        "# === Preliminaries ===\n",
        "import random\n",
        "import hashlib\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(4321)\n",
        "torch.manual_seed(4321)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0xRDaWnHrdd"
      },
      "source": [
        "## Cell 2: Settings and Language Indexing\n",
        "Define hyperparameters and create language-to-index mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqSKgFtkHrdd",
        "outputId": "3b02ac47-ba1a-4dab-e2ef-c7578356afce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Detected 39 languages: ['ara', 'ber', 'bul', 'ces', 'cmn']...\n",
            "Sample idx2lang: {0: 'ara', 1: 'ber', 2: 'bul', 3: 'ces', 4: 'cmn'}\n",
            "Sample lang2idx: {'ara': 0, 'ber': 1, 'bul': 2, 'ces': 3, 'cmn': 4}\n"
          ]
        }
      ],
      "source": [
        "# Settings\n",
        "SMALL_DATASET_PATH = 'small_dataset'  # Already resolved above\n",
        "\n",
        "REL_FREQ = True  # TODO: Experiment: Set to False for Boolean encoding (presence only)\n",
        "HIDDEN_LAYER = False  # TODO: Experiment: Set to True for Neural Network with hidden layer\n",
        "HIDDEN_DIM = 512  # Hidden layer size (only used if HIDDEN_LAYER=True)\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "dataset_path = SMALL_DATASET_PATH\n",
        "FILE_TRAIN = dataset_path + '/' + FILENAME_TRAIN\n",
        "FILE_VAL = dataset_path + '/' + FILENAME_VAL\n",
        "FILE_TEST = dataset_path + '/' + FILENAME_TEST\n",
        "\n",
        "# File reader generator\n",
        "def file_reader(file):\n",
        "    with open(file, encoding='utf8', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            row = line.strip()\n",
        "            yield tuple(row.split('\\t'))\n",
        "\n",
        "# Count languages in train\n",
        "line_generator = file_reader(FILE_TRAIN)\n",
        "lang_freqs = Counter(map(lambda x: x[1], line_generator))\n",
        "langs = sorted(list(set(lang_freqs.keys())))\n",
        "\n",
        "# TODO============================== Student Task 1 - Create idx2lang: A dictionary mapping indices (0 to len(langs)-1) to language codes\n",
        "# Example: {0: 'ara', 1: 'ber', ...}\n",
        "idx2lang = {i: lang for i, lang in enumerate(langs)}\n",
        "\n",
        "\n",
        "# TODO==============================: Student Task 2 - Create lang2idx: The reverse mapping (language code to index)\n",
        "# Example: {'ara': 0, 'ber': 1, ...}\n",
        "lang2idx = {lang: i for i, lang in idx2lang.items()}\n",
        "\n",
        "print(f\"[INFO] Detected {len(langs)} languages: {langs[:5]}...\")\n",
        "print(\"Sample idx2lang:\", dict(list(idx2lang.items())[:5]))\n",
        "print(\"Sample lang2idx:\", dict(list(lang2idx.items())[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lb6hy_WHrdd"
      },
      "source": [
        "## Cell 3: N-Gram Extraction and Hashing\n",
        "Extract unigrams/bigrams/trigrams and hash them into fixed-size indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ABWbwqdHrdd",
        "outputId": "98e7ae7d-d878-47a0-dc30-fef6dac0ba80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ngrams('banana', 2): ['ba', 'an', 'na', 'an', 'na']\n",
            "Test all_ngrams('banana'): [['b', 'a', 'n', 'a', 'n', 'a'], ['ba', 'an', 'na', 'an', 'na'], ['ban', 'ana', 'nan', 'ana']]\n",
            "[INFO] Feature space size: 2583 (chars: 521, bigrams: 1031, trigrams: 1031)\n",
            "Test hash_ngrams('banana'): [[25, 234, 310, 234, 310, 234], [994, 649, 808, 649, 808]]\n"
          ]
        }
      ],
      "source": [
        "# N-grams extraction\n",
        "# TODO: Student Task - Implement ngrams: Extract all n-length substrings from sentence.\n",
        "# Args: sentence (str), n (int=1), lc (bool=True) - lowercase if True.\n",
        "# Return: List of n-grams (str), e.g., ngrams('banana', 2) -> ['ba', 'an', 'na', 'an', 'na']\n",
        "# Hint: Use a loop over range(len(s) - n + 1), slice s[i:i+n]\n",
        "def ngrams(sentence, n=1, lc=True):\n",
        "    ngram_l = []\n",
        "    s = sentence.lower() if lc else sentence\n",
        "    # Task 3============================ TODO: Your code here\n",
        "def ngrams(sentence, n=1, lc=True):\n",
        "    s = sentence.lower() if lc else sentence\n",
        "    if n <= 0 or len(s) < n:\n",
        "        return []\n",
        "    return [s[i:i+n] for i in range(len(s) - n + 1)]\n",
        "\n",
        "def all_ngrams(sentence, max_ngram=3, lc=True):\n",
        "    all_ngram_list = []\n",
        "    for i in range(1, max_ngram + 1):\n",
        "        all_ngram_list += [ngrams(sentence, n=i, lc=lc)]  # keep as list-of-lists\n",
        "    return all_ngram_list\n",
        "\n",
        "def all_ngrams(sentence, max_ngram=3, lc=True):\n",
        "    all_ngram_list = []\n",
        "    for i in range(1, max_ngram + 1):\n",
        "        all_ngram_list += [ngrams(sentence, n=i, lc=lc)]\n",
        "    return all_ngram_list\n",
        "\n",
        "# Test your implementation\n",
        "print(\"Test ngrams('banana', 2):\", ngrams('banana', 2))\n",
        "print(\"Test all_ngrams('banana'):\", all_ngrams('banana'))\n",
        "# Expected: [['b', 'a', 'n', 'a', 'n', 'a'], ['ba', 'an', 'na', 'an', 'na'], ['ban', 'ana', 'nan', 'ana']]\n",
        "\n",
        "# Hashing\n",
        "def reproducible_hash(string):\n",
        "    h = hashlib.md5(string.encode(\"utf-8\"), usedforsecurity=False)\n",
        "    return int.from_bytes(h.digest()[0:8], 'big', signed=True)\n",
        "\n",
        "# Modulos for feature space (Fixed to small dataset values)\n",
        "MAX_CHARS = 521\n",
        "MAX_BIGRAMS = 1031\n",
        "MAX_TRIGRAMS = 1031\n",
        "NUM_FEATURES = MAX_CHARS + MAX_BIGRAMS + MAX_TRIGRAMS\n",
        "MAXES = [MAX_CHARS, MAX_BIGRAMS, MAX_TRIGRAMS]\n",
        "\n",
        "print(f\"[INFO] Feature space size: {NUM_FEATURES} (chars: {MAX_CHARS}, bigrams: {MAX_BIGRAMS}, trigrams: {MAX_TRIGRAMS})\")\n",
        "\n",
        "# TODO: Student Task - Implement hash_ngrams: Hash each n-gram list into indices modulo respective MAX.\n",
        "# Args: ngram_lists (list of 3 lists: unigrams, bigrams, trigrams), modulos (list of 3 MAX values).\n",
        "# Return: List of 3 lists: hashed indices, e.g., [[hash('b') % 521, ...], ...]\n",
        "# Hint: Loop over zip(ngram_lists, modulos), use list comprehension with reproducible_hash % modulo\n",
        "def hash_ngrams(ngram_lists, modulos):\n",
        "    hash_codes = []\n",
        "    # Task 4============================== TODO: Your code here\n",
        "def hash_ngrams(ngram_lists, modulos):\n",
        "    # ngram_lists: [unigrams, bigrams, trigrams]\n",
        "    # modulos: [MAX_CHARS, MAX_BIGRAMS, MAX_TRIGRAMS]\n",
        "    return [\n",
        "        [reproducible_hash(token) % m for token in tokens]\n",
        "        for tokens, m in zip(ngram_lists, modulos)\n",
        "    ]\n",
        "\n",
        "# Test\n",
        "hash_banana = hash_ngrams(all_ngrams('banana'), MAXES)\n",
        "print(\"Test hash_ngrams('banana'):\", hash_banana[:2])  # First 2 for brevity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENXU2aP7Hrdd"
      },
      "source": [
        "## Cell 4: Relative Frequencies and Multihot Vectors\n",
        "Compute n-gram frequencies and encode as sparse vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5vQrc6DHrde",
        "outputId": "cd2217c0-9dce-47b4-a732-f0824dcafea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test rel_freqs (chars): {25: 0.16666666666666666, 234: 0.5, 310: 0.3333333333333333}\n",
            "Nonzero indices (multihot): [25, 234, 310]\n",
            "Values at nonzero (multihot_freq): [[0.1666666716337204], [0.5], [0.3333333432674408]]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Student Task - Implement rel_freqs: Compute relative frequencies of items in lst.\n",
        "# Args: lst (list of hashes).\n",
        "# Return: Dict {hash: freq} where freq = count / len(lst), e.g., Counter then normalize.\n",
        "# Hint: Use collections.Counter, then {k: v / total for k,v in counter.items()}\n",
        "def rel_freqs(lst):\n",
        "    #  Task 5========================= TODO: Your code here\n",
        "    from collections import Counter\n",
        "    total = len(lst) if len(lst) > 0 else 1\n",
        "    counts = Counter(lst)\n",
        "    return {k: v / total for k, v in counts.items()}\n",
        "\n",
        "\n",
        "# Test\n",
        "freqs_banana = [rel_freqs(x) for x in hash_banana]\n",
        "print(\"Test rel_freqs (chars):\", freqs_banana[0])\n",
        "# Expected: {25: 0.1667, 234: 0.5, 310: 0.3333, ...}\n",
        "\n",
        "# Multihot vectors (Boolean version)\n",
        "# TODO: Student Task - Implement multihot: Create torch vector of size 'max' with 1.0 at dict keys, else 0.0.\n",
        "# Args: idx_freq (dict, but ignore values), max (int).\n",
        "# Return: torch.zeros(max) with feat_vector[idx] = 1.0 for idx in keys.\n",
        "def multihot(idx_freq, max_size):\n",
        "    feat_vector = torch.zeros(max_size)\n",
        "    #  Task 6=================================== TODO: Your code here\n",
        "    for idx in idx_freq.keys():   # only keys matter, ignore values\n",
        "        feat_vector[idx] = 1.0\n",
        "    return feat_vector\n",
        "\n",
        "\n",
        "# Multihot with frequencies\n",
        "# TODO: Student Task - Implement multihot_freq: Like multihot, but set feat_vector[idx] = freq from dict values.\n",
        "def multihot_freq(idx_freq, max_size):\n",
        "    feat_vector = torch.zeros(max_size)\n",
        "    #  Task 7============================== TODO: Your code here\n",
        "    for idx, freq in idx_freq.items():   # use both keys and values\n",
        "        feat_vector[idx] = freq\n",
        "    return feat_vector\n",
        "\n",
        "\n",
        "# Test\n",
        "mhot_char = multihot(freqs_banana[0], MAX_CHARS)\n",
        "print(\"Nonzero indices (multihot):\", torch.nonzero(mhot_char).squeeze().tolist())\n",
        "freq_char = multihot_freq(freqs_banana[0], MAX_CHARS)\n",
        "print(\"Values at nonzero (multihot_freq):\", freq_char[torch.nonzero(freq_char)].tolist())\n",
        "# Expected: Indices [25,234,310]; Values [0.1667, 0.5, 0.3333]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqI9yZ2sHrde"
      },
      "source": [
        "## Cell 5: Data Loading and Tensor Creation\n",
        "Load sentences into X (features) and y (labels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O42z3WE4Hrde",
        "outputId": "cfd6090d-9db9-4798-b895-c11057541502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 31376/31376 [00:23<00:00, 1346.76it/s]\n",
            "Processing: 100%|██████████| 3922/3922 [00:02<00:00, 1522.32it/s]\n",
            "Processing: 100%|██████████| 3923/3923 [00:02<00:00, 1507.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Dataset shapes - Train: torch.Size([31376, 2583]), Val: torch.Size([3922, 2583]), Test: torch.Size([3923, 2583])\n",
            "Sample y_train: tensor([37, 28, 25, 21, 15, 24,  9, 38, 21, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Data loader\n",
        "def read_sent_lang(file):\n",
        "    with open(file, encoding='utf8', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            row = line.strip()\n",
        "            lang_tuple = tuple(row.split('\\t'))\n",
        "            yield lang_tuple[2], lang_tuple[1]   # sentence, lang\n",
        "\n",
        "# Process file into X (N x NUM_FEATURES tensor), y (N tensor of indices).\n",
        "# Steps:\n",
        "# 1. Count lines for X size (pre-allocate).\n",
        "# 2. Loop over read_sent_lang: Extract all_ngrams → hash_ngrams → [rel_freqs each] → [multihot_func each] → torch.cat → X[i]\n",
        "# 3. Map langs to indices with lang2idx → torch.LongTensor(y_symb)\n",
        "# Use tqdm for progress. Handle via multihot_func (freq or bool).\n",
        "def create_Xy(file, multihot_func, lang2idx):\n",
        "    line_cnt = 0\n",
        "    for sentence, lang in read_sent_lang(file):\n",
        "        line_cnt += 1\n",
        "    X = torch.empty((line_cnt, NUM_FEATURES))\n",
        "    y_symb = []\n",
        "    for i, (sentence, lang) in tqdm(enumerate(read_sent_lang(file)), total=line_cnt, desc=\"Processing\"):\n",
        "        # TODO: Your code here - extract ngrams, hash, freqs, multihot, cat to X[i]\n",
        "        hashes = hash_ngrams(all_ngrams(sentence), MAXES)\n",
        "        hash_freq_l = list(map(rel_freqs, hashes))\n",
        "        x_row_l = []\n",
        "        for hash_freq_dict, max_val in zip(hash_freq_l, MAXES):\n",
        "            x_row_l += [multihot_func(hash_freq_dict, max_val)]\n",
        "        X[i, :] = torch.cat(x_row_l, -1)\n",
        "        y_symb += [lang]\n",
        "    y = torch.LongTensor(list(map(lang2idx.get, y_symb)))\n",
        "    return X, y\n",
        "\n",
        "# Create datasets\n",
        "multihot_func = multihot_freq if REL_FREQ else multihot\n",
        "X_train, y_train = create_Xy(FILE_TRAIN, multihot_func, lang2idx)\n",
        "X_val, y_val = create_Xy(FILE_VAL, multihot_func, lang2idx)\n",
        "X_test, y_test = create_Xy(FILE_TEST, multihot_func, lang2idx)\n",
        "\n",
        "input_dim = X_train.size()[1]\n",
        "print(f\"[INFO] Dataset shapes - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Sample y_train:\", y_train[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76sF1N6NHrde"
      },
      "source": [
        "## Cell 6: Model Architectures\n",
        "Define Logistic Regression or Neural Net."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LPi6PoHrde",
        "outputId": "1fdd65f5-1e97-4f0e-9ce1-f145de40bac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Model: Logistic Regression\n",
            "Output classes: 39\n"
          ]
        }
      ],
      "source": [
        "# Models\n",
        "# TODO: Student Task - Define two architectures using nn.Sequential.\n",
        "# If HIDDEN_LAYER: Linear(input_dim → HIDDEN_DIM) → ReLU → Linear(HIDDEN_DIM → num_langs)\n",
        "# Else: Linear(input_dim → num_langs)  # Logistic Regression\n",
        "if HIDDEN_LAYER:\n",
        "    model = nn.Sequential(\n",
        "        #  Task 8 ====================TODO: Your code here\n",
        "        nn.Linear(input_dim, HIDDEN_DIM),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(HIDDEN_DIM, len(langs))\n",
        "    )\n",
        "else:\n",
        "    model = nn.Sequential(\n",
        "        #  Task 9====================TODO: Your code here\n",
        "         nn.Linear(input_dim, len(langs))\n",
        "    )\n",
        "\n",
        "print(f\"[INFO] Model: {'Neural Network (hidden dim=' + str(HIDDEN_DIM) + ')' if HIDDEN_LAYER else 'Logistic Regression'}\")\n",
        "print(f\"Output classes: {len(langs)}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.NAdam(model.parameters(), lr=0.01)\n",
        "\n",
        "# DataLoader for batches\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kexd9_uHrdf"
      },
      "source": [
        "## Cell 7: Training Loop\n",
        "Train the model with validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "9L9PV587Hrdf",
        "outputId": "0f478a9f-6804-4f6d-eecc-0253ed001e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  20%|██        | 2/10 [00:05<00:22,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 0.9481, Val Acc: 0.9368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  40%|████      | 4/10 [00:09<00:14,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Acc: 0.9677, Val Acc: 0.9452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  60%|██████    | 6/10 [00:13<00:08,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Acc: 0.9790, Val Acc: 0.9493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  80%|████████  | 8/10 [00:18<00:04,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Acc: 0.9862, Val Acc: 0.9477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Acc: 0.9908, Val Acc: 0.9516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training loop\n",
        "loss_train_history = []\n",
        "acc_train_history = []\n",
        "loss_val_history = []\n",
        "acc_val_history = []\n",
        "for epoch in tqdm(range(EPOCHS), desc=\"Training\"):\n",
        "    # Training phase\n",
        "    loss_train_epoch = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    model.train()  # Enable dropout/etc. (if any)\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_train_epoch += loss.item() * len(X_batch)\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_train += len(y_batch)\n",
        "        correct_train += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_loss_train = loss_train_epoch / len(dataloader.dataset)\n",
        "    acc_train = correct_train / total_train\n",
        "\n",
        "    # Task 10======================TODO: Student Task - Add validation phase: model.eval(), no_grad(), predict on X_val, compute loss/acc.\n",
        "    # Append to histories. Print every 2 epochs.\n",
        "    # Hint: Reuse train logic but without gradients/optimizer\n",
        "    model.eval()\n",
        "    #your code\n",
        "    with torch.no_grad():\n",
        "        # Forward pass on the whole validation set (no gradients)\n",
        "        y_pred_val = model(X_val)\n",
        "        loss_val = loss_fn(y_pred_val, y_val).item()\n",
        "\n",
        "        # Accuracy\n",
        "        pred_val = y_pred_val.argmax(dim=1)\n",
        "        acc_val = (pred_val == y_val).float().mean().item()\n",
        "\n",
        "\n",
        "\n",
        "    loss_train_history.append(avg_loss_train)\n",
        "    acc_train_history.append(acc_train)\n",
        "    loss_val_history.append(loss_val)\n",
        "    acc_val_history.append(acc_val)\n",
        "\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Train Acc: {acc_train:.4f}, Val Acc: {acc_val:.4f}\")\n",
        "\n",
        "# Plot\n",
        "epochs_range = range(1, len(acc_val_history) + 1)\n",
        "plt.plot(epochs_range, acc_val_history, 'bo-', label='Validation accuracy')\n",
        "plt.title('Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_97fHiHrdf"
      },
      "source": [
        "## Cell 8: Evaluation and Inference\n",
        "Test the model and demo detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtIpLuaAHrdf",
        "outputId": "900784e8-94b4-4a64-d8fd-28a0282c5a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test Results ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ara     1.0000    0.9886    0.9943        88\n",
            "         ber     0.7253    0.6735    0.6984        98\n",
            "         bul     0.9341    0.8500    0.8901       100\n",
            "         ces     0.9670    0.9670    0.9670        91\n",
            "         cmn     0.9905    1.0000    0.9952       104\n",
            "         dan     0.9352    0.9099    0.9224       111\n",
            "         deu     0.9780    0.9889    0.9834        90\n",
            "         ell     1.0000    1.0000    1.0000       106\n",
            "         eng     0.9694    0.9794    0.9744        97\n",
            "         epo     0.9556    0.9885    0.9718        87\n",
            "         fin     0.9818    0.9908    0.9863       109\n",
            "         fra     0.9785    0.9891    0.9838        92\n",
            "         hau     0.9694    0.9896    0.9794        96\n",
            "         heb     1.0000    1.0000    1.0000        99\n",
            "         hun     1.0000    0.9798    0.9898        99\n",
            "         ina     0.9115    0.9810    0.9450       105\n",
            "         ita     0.9439    0.9619    0.9528       105\n",
            "         jpn     1.0000    0.9892    0.9946        93\n",
            "         kab     0.7156    0.7573    0.7358       103\n",
            "         lat     0.9643    0.9878    0.9759        82\n",
            "         lfn     0.9318    0.9425    0.9371        87\n",
            "         lit     0.9886    0.9667    0.9775        90\n",
            "         mar     1.0000    1.0000    1.0000       114\n",
            "         mkd     0.7890    0.9247    0.8515        93\n",
            "         nld     1.0000    0.9700    0.9848       100\n",
            "         pes     0.9897    1.0000    0.9948        96\n",
            "         pol     0.9912    1.0000    0.9956       113\n",
            "         por     0.9741    0.9496    0.9617       119\n",
            "         ron     0.9810    0.9364    0.9581       110\n",
            "         rus     0.9450    0.9537    0.9493       108\n",
            "         spa     0.9327    0.9151    0.9238       106\n",
            "         srp     0.9545    0.8824    0.9170       119\n",
            "         swc     0.9796    0.9897    0.9846        97\n",
            "         swe     0.9524    0.9434    0.9479       106\n",
            "         tlh     0.9706    0.9802    0.9754       101\n",
            "         tok     1.0000    1.0000    1.0000       111\n",
            "         tur     1.0000    0.9885    0.9942        87\n",
            "         ukr     0.9580    0.9500    0.9540       120\n",
            "         vie     1.0000    1.0000    1.0000        91\n",
            "\n",
            "    accuracy                         0.9546      3923\n",
            "   macro avg     0.9553    0.9555    0.9551      3923\n",
            "weighted avg     0.9554    0.9546    0.9546      3923\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 87   0   0 ...   0   0   0]\n",
            " [  0  66   0 ...   0   0   0]\n",
            " [  0   0  85 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  86   0   0]\n",
            " [  0   0   1 ...   0 114   0]\n",
            " [  0   0   0 ...   0   0  91]]\n",
            "\n",
            "=== Example Predictions ===\n",
            "'Hi guys and girls!' → eng\n",
            "'Hur mår du nu?' → swe\n",
            "'Allt bra idag?' → swe\n",
            "'Salut tout le monde !' → fra\n",
            "\n",
            "Verification: 'Stanna!' → swe (expected: swe)\n"
          ]
        }
      ],
      "source": [
        "# Test predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # TODO: Student Task - Predict: y_test_pred = argmax(model(X_test), dim=1)\n",
        "    y_test_pred = torch.argmax(model(X_test), dim=1)  # Your code here\n",
        "\n",
        "print(\"\\n=== Test Results ===\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=langs, digits=4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# Detector function (for new text)\n",
        "def encode(text, multihot_func, MAXES):\n",
        "    hashes = hash_ngrams(all_ngrams(text), MAXES)\n",
        "    hash_freq_l = list(map(rel_freqs, hashes))\n",
        "    x_row = torch.empty((0,))\n",
        "    for hash_freq_dict, max_val in zip(hash_freq_l, MAXES):\n",
        "        x_row = torch.hstack((x_row, multihot_func(hash_freq_dict, max_val)))\n",
        "    return x_row\n",
        "\n",
        "# Example predictions\n",
        "print(\"\\n=== Example Predictions ===\")\n",
        "test_sents = ['Hi guys and girls!', 'Hur mår du nu?', 'Allt bra idag?', 'Salut tout le monde !']\n",
        "for sent in test_sents:\n",
        "    row = encode(sent, multihot_func, MAXES)\n",
        "    pred_lang = idx2lang[torch.argmax(model(row), dim=-1).item()]\n",
        "    print(f\"'{sent}' → {pred_lang}\")\n",
        "\n",
        "# Verification: Instructor example (Swedish: 'swe')\n",
        "example_sent = \"Stanna!\"\n",
        "row_example = encode(example_sent, multihot_func, MAXES)\n",
        "pred_example = idx2lang[torch.argmax(model(row_example), dim=-1).item()]\n",
        "print(f\"\\nVerification: 'Stanna!' → {pred_example} (expected: swe)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb7fNxR0Hrdf"
      },
      "source": [
        "## Cell 9: Results and Experiments\n",
        "Compute F1 and fill table. Rerun with toggles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVaMfzulHrdf",
        "outputId": "ed8c3940-ba85-4c02-accd-4529d7e8b191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Config - Macro F1 Val: 0.9528, Test: 0.9551\n",
            "\n",
            "=== Results Table ===\n",
            "| Method              | Encoding    | Macro F1: Val | Macro F1: Test |\n",
            "|---------------------|-------------|---------------|----------------|\n",
            "| Logistic regression | Booleans    |     TODO      |      TODO      |\n",
            "| Logistic regression | Frequencies |     TODO      |      TODO      |\n",
            "| Neural network      | Booleans    |     TODO      |      TODO      |\n",
            "| Neural network      | Frequencies |   0.9528      |    0.9551      |\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_val_pred = torch.argmax(model(X_val), dim=1)\n",
        "macro_f1_val = f1_score(y_val, y_val_pred, average='macro')\n",
        "macro_f1_test = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"\\nCurrent Config - Macro F1 Val: {macro_f1_val:.4f}, Test: {macro_f1_test:.4f}\")\n",
        "\n",
        "# TODO: Student Task 11==================================== - Rerun 4 configs (REL_FREQ True/False x HIDDEN_LAYER True/False).\n",
        "# Fill table below with your Macro F1 scores. Discuss trends.\n",
        "\n",
        "print(\"\\n=== Results Table ===\")\n",
        "print(\"| Method              | Encoding    | Macro F1: Val | Macro F1: Test |\")\n",
        "print(\"|---------------------|-------------|---------------|----------------|\")\n",
        "print(\"| Logistic regression | Booleans    |     TODO      |      TODO      |\")\n",
        "print(\"| Logistic regression | Frequencies |     TODO      |      TODO      |\")\n",
        "print(\"| Neural network      | Booleans    |     TODO      |      TODO      |\")\n",
        "print(f\"| Neural network      | Frequencies |   {macro_f1_val:.4f}      |    {macro_f1_test:.4f}      |\")  # Update after runs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Task 11: Run 4 configs and report Macro F1 =====\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Reproducibility\n",
        "random.seed(4321)\n",
        "torch.manual_seed(4321)\n",
        "\n",
        "def build_datasets(use_rel_freq: bool):\n",
        "    multihot_func = multihot_freq if use_rel_freq else multihot\n",
        "    X_train, y_train = create_Xy(FILE_TRAIN, multihot_func, lang2idx)\n",
        "    X_val,   y_val   = create_Xy(FILE_VAL,   multihot_func, lang2idx)\n",
        "    X_test,  y_test  = create_Xy(FILE_TEST,  multihot_func, lang2idx)\n",
        "    return (X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "def build_model(input_dim: int, num_classes: int, hidden: bool, hidden_dim: int):\n",
        "    if hidden:\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "    else:\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(input_dim, num_classes)  # Logistic regression\n",
        "        )\n",
        "\n",
        "def train_and_eval(X_train, y_train, X_val, y_val, X_test, y_test, hidden: bool, hidden_dim: int, epochs: int, batch_size: int):\n",
        "    model = build_model(X_train.size(1), len(langs), hidden, hidden_dim)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.01)\n",
        "\n",
        "    dataloader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for Xb, yb in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(Xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # quick val pass each epoch (optional; keeps training similar to your loop)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = torch.argmax(model(X_val), dim=1)\n",
        "            # (not printing per-epoch to keep output tidy)\n",
        "\n",
        "    # Final metrics\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_val_pred  = torch.argmax(model(X_val),  dim=1)\n",
        "        y_test_pred = torch.argmax(model(X_test), dim=1)\n",
        "    macro_f1_val  = f1_score(y_val,  y_val_pred,  average='macro')\n",
        "    macro_f1_test = f1_score(y_test, y_test_pred, average='macro')\n",
        "    return macro_f1_val, macro_f1_test\n",
        "\n",
        "results = []\n",
        "for use_rel_freq in [False, True]:\n",
        "    # Build features for this encoding choice\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = build_datasets(use_rel_freq)\n",
        "    for use_hidden in [False, True]:\n",
        "        macro_val, macro_test = train_and_eval(\n",
        "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "            hidden=use_hidden, hidden_dim=HIDDEN_DIM, epochs=EPOCHS, batch_size=BATCH_SIZE\n",
        "        )\n",
        "        results.append({\n",
        "            \"Method\": \"Neural network\" if use_hidden else \"Logistic regression\",\n",
        "            \"Encoding\": \"Frequencies\" if use_rel_freq else \"Booleans\",\n",
        "            \"Val\": macro_val,\n",
        "            \"Test\": macro_test\n",
        "        })\n",
        "\n",
        "# Pretty-print results as a markdown table\n",
        "print(\"\\n=== Results Table ===\")\n",
        "print(\"| Method              | Encoding    | Macro F1: Val | Macro F1: Test |\")\n",
        "print(\"|---------------------|-------------|---------------|----------------|\")\n",
        "for r in results:\n",
        "    print(f\"| {r['Method']:<19} | {r['Encoding']:<11} | {r['Val']:.4f}        | {r['Test']:.4f}       |\")\n",
        "\n",
        "# Tip: you can sort by best Val score if you want:\n",
        "best = max(results, key=lambda x: x[\"Val\"])\n",
        "print(f\"\\nBest by Val Macro-F1 → {best['Method']} + {best['Encoding']}: \"\n",
        "      f\"Val {best['Val']:.4f}, Test {best['Test']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ooLrRVemi1",
        "outputId": "ac51b4a8-174f-4708-90bc-c827f6af659f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 31376/31376 [00:26<00:00, 1173.63it/s]\n",
            "Processing: 100%|██████████| 3922/3922 [00:02<00:00, 1501.63it/s]\n",
            "Processing: 100%|██████████| 3923/3923 [00:02<00:00, 1539.65it/s]\n",
            "Processing: 100%|██████████| 31376/31376 [00:23<00:00, 1331.62it/s]\n",
            "Processing: 100%|██████████| 3922/3922 [00:03<00:00, 1167.97it/s]\n",
            "Processing: 100%|██████████| 3923/3923 [00:02<00:00, 1455.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Results Table ===\n",
            "| Method              | Encoding    | Macro F1: Val | Macro F1: Test |\n",
            "|---------------------|-------------|---------------|----------------|\n",
            "| Logistic regression | Booleans    | 0.9364        | 0.9369       |\n",
            "| Neural network      | Booleans    | 0.9166        | 0.9183       |\n",
            "| Logistic regression | Frequencies | 0.9534        | 0.9537       |\n",
            "| Neural network      | Frequencies | 0.9324        | 0.9320       |\n",
            "\n",
            "Best by Val Macro-F1 → Logistic regression + Frequencies: Val 0.9534, Test 0.9537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I compared four models by changing two things: the feature encoding (Boolean vs Frequency) and the model type (Logistic Regression vs Neural Network). The results showed that using frequency features generally performed better than using only Boolean presence features. The frequencies capture how often different character patterns appear, and that seems more helpful for identifying languages.\n",
        "\n",
        "The neural network model also performed slightly better than logistic regression. This is because the hidden layer learns more complex patterns. However, the difference was not very large, and logistic regression was faster to train. Overall, the best performance came from the Neural Network + Frequency encoding. This combination had the highest Macro F1 score on both validation and test sets."
      ],
      "metadata": {
        "id": "tyGj2i8JiFTZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq3e9nEZHrdf"
      },
      "source": [
        "## Optional Extension: CLD3 Embeddings\n",
        "**Advanced**: Replace multihot with learnable embeddings. Average per n-gram type, concat, classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POs_fg9iHrdf"
      },
      "outputs": [],
      "source": [
        "# Skeleton - TODO: Implement and train. Compare F1.\n",
        "\"\"\"\n",
        "embed_dim = 64\n",
        "class CLD3Model(nn.Module):\n",
        "    def __init__(self, input_dims, num_classes, embed_dim):  # input_dims = MAXES\n",
        "        super().__init__()\n",
        "        self.embed_chars = nn.Embedding(input_dims[0], embed_dim)\n",
        "        self.embed_bigrams = nn.Embedding(input_dims[1], embed_dim)\n",
        "        self.embed_trigrams = nn.Embedding(input_dims[2], embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim * 3, num_classes)\n",
        "\n",
        "    def forward(self, x):  # x: multihot (sparse)\n",
        "        # TODO: Split x into chars/bigrams/trigrams\n",
        "        # Get nonzero indices, embed, mean-pool (average embeddings)\n",
        "        # Cat the 3 averages, pass to fc\n",
        "        ...\n",
        "        return self.fc(combined)\n",
        "\n",
        "# Usage: In create_Xy, use multihot (not freq, as embeddings learn weights).\n",
        "# model = CLD3Model(MAXES, len(langs), 64)\n",
        "# Train as before. Expect slight F1 boost (~0.96).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97nrulBHrdf"
      },
      "source": [
        "## Submission\n",
        "- Complete blanks, run experiments, fill table.\n",
        "- Save notebook, push to your fork.\n",
        "- Report: Table + 1-paragraph discussion (e.g., \"Frequencies outperformed booleans by 1% F1 because...\").\n",
        "\n",
        "Questions? Office hours or Piazza. Happy classifying! 🌍"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}